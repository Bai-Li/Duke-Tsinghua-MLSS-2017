{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow-Slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TensorFlow-Slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) is a high-level API for building TensorFlow models. TF-Slim makes defining models in TensorFlow easier, cutting down on the number of lines required to define models and reducing overall clutter. In particular, TF-Slim shines in image domain problems, and weights pre-trained on the [ImageNet dataset](http://www.image-net.org/) for many famous CNN architectures are provided for [download](https://github.com/tensorflow/models/tree/master/slim#pre-trained-models).\n",
    "\n",
    "To show these benefits, this tutorial will focus on [VGG-16](https://arxiv.org/abs/1409.1556). This style of architecture came in 2nd during the 2014 ImageNet Large Scale Visual Recognition Challenge and is famous for its simplicity and depth. The model looks like this:\n",
    "\n",
    "![vgg16](Figures/vgg16.png)\n",
    "\n",
    "The architecture is pretty straight-forward: simply stack multiple 3x3 convolutional filters one after another, interleave with 2x2 maxpools, double the number of convolutional filters after each maxpool, flatten, and finish with fully connected layers. A couple ideas behind this model:\n",
    "\n",
    "- Instead of using larger filters, VGG notes that the receptive field of two stacked layers of 3x3 filters is 5x5, and with 3 layers, 7x7. Using 3x3's allows VGG to insert additional non-linearities and requires fewer weight parameters to learn.\n",
    "\n",
    "- Doubling the width of the network every time the features are spatially downsampled (maxpooled) gives the model more representational capacity while achieving spatial compression.\n",
    "\n",
    "In code, setting up the computation graph for prediction with just TensorFlow Core API is kind of a lot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Set up the data loading:\n",
    "images, labels = ...\n",
    "\n",
    "# Define the model\n",
    "with tf.name_scope('conv1_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 3, 64], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv1 = tf.nn.relu(bias, name=scope)\n",
    "    \n",
    "with tf.name_scope('conv1_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 64], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv1 = tf.nn.relu(bias, name=scope)\n",
    "    \n",
    "pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool1')\n",
    "    \n",
    "with tf.name_scope('conv2_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 128], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv2 = tf.nn.relu(bias, name=scope)\n",
    "    \n",
    "with tf.name_scope('conv2_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 128], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv2 = tf.nn.relu(bias, name=scope)\n",
    "    \n",
    "pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "    \n",
    "with tf.name_scope('conv3_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 256], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(pool2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv3 = tf.nn.relu(bias, name=scope)\n",
    "    \n",
    "with tf.name_scope('conv3_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv3 = tf.nn.relu(bias, name=scope)\n",
    "    \n",
    "with tf.name_scope('conv3_3') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv3 = tf.nn.relu(bias, name=scope)\n",
    "    \n",
    "pool3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool3')\n",
    "    \n",
    "with tf.name_scope('conv4_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 512], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(pool3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv4 = tf.nn.relu(bias, name=scope)\n",
    "    \n",
    "with tf.name_scope('conv4_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv4 = tf.nn.relu(bias, name=scope)\n",
    "    \n",
    "with tf.name_scope('conv4_3') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv4 = tf.nn.relu(bias, name=scope)\n",
    "    \n",
    "pool4 = tf.nn.max_pool(conv4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool4')\n",
    "\n",
    "with tf.name_scope('conv5_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(pool4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv5 = tf.nn.relu(bias, name=scope)\n",
    "    \n",
    "with tf.name_scope('conv5_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv5, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv5 = tf.nn.relu(bias, name=scope)\n",
    "    \n",
    "with tf.name_scope('conv5_3') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv5, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv5 = tf.nn.relu(bias, name=scope)\n",
    "    \n",
    "pool5 = tf.nn.max_pool(conv5, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool5')\n",
    "    \n",
    "with tf.name_scope('fc_6') as scope:\n",
    "    flat = tf.reshape(pool5, [-1, 7*7*512])\n",
    "    weights = tf.Variable(tf.truncated_normal([7*7*512, 4096], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    mat = tf.matmul(flat, weights)\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[4096], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(mat, biases)\n",
    "    fc6 = tf.nn.relu(bias, name=scope)\n",
    "    fc6_drop = tf.nn.dropout(fc6, keep_prob=0.5, name='dropout')\n",
    "\n",
    "with tf.name_scope('fc_7') as scope:\n",
    "    weights = tf.Variable(tf.truncated_normal([4096, 4096], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    mat = tf.matmul(fc6, weights)\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[4096], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(mat, biases)\n",
    "    fc7 = tf.nn.relu(bias, name=scope)\n",
    "    fc7_drop = tf.nn.dropout(fc7, keep_prob=0.5, name='dropout')\n",
    "    \n",
    "with tf.name_scope('fc_8') as scope:\n",
    "    weights = tf.Variable(tf.truncated_normal([4096, 1000], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "    mat = tf.matmul(fc7, weights)\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[1000], dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(mat, biases)\n",
    "\n",
    "predictions = bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding every line of this model isn't important. The main to notice is how much space this takes up. Several of the above lines (conv2d, bias_add, relu, maxpool) can obviously be combined to cut down on the size a bit, you could also try to compress the code with some clever for looping, but all at the cost of sacrificing readability. With this much code, there is high potential for bugs or typos (to be honest, there are probably a few up there^), and modifying or refactoring the code becomes a huge pain.\n",
    "\n",
    "By the way, although VGG-16's paper was titled \"Very Deep Convolutional Networks for Large-Scale Image Recognition\", it isn't even considered a particularly deep network by today's standards. [Residual Networks](https://arxiv.org/abs/1512.03385) (2015) started beating state-of-the-art results with 50, 101, and 152 layers in their first incarnation, and then really went off the deep end and got up to 1001 layers and beyond. I think I'll spare you from me typing out the uncompressed TensorFlow Core code for that.\n",
    "\n",
    "Enter TF-Slim. The exact same VGG-16 model can be expressed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "def vgg16(inputs):\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                        activation_fn=tf.nn.relu,\n",
    "                        weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),\n",
    "                        weights_regularizer=slim.l2_regularizer(0.0005)):\n",
    "        net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "        net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "        net = slim.fully_connected(net, 4096, scope='fc6')\n",
    "        net = slim.dropout(net, 0.5, scope='dropout6')\n",
    "        net = slim.fully_connected(net, 4096, scope='fc7')\n",
    "        net = slim.dropout(net, 0.5, scope='dropout7')\n",
    "        net = slim.fully_connected(net, 1000, activation_fn=None, scope='fc8')\n",
    "    return net\n",
    "\n",
    "# Set up the data loading:\n",
    "images, labels = ...\n",
    "\n",
    "# Define the model:\n",
    "predictions = vgg16(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much cleaner. For the TF-Slim version, it's much more obvious what the network is doing, writing it is faster, and typos and bugs are much less likely.\n",
    "\n",
    "Things to notice:\n",
    "\n",
    "- Weight and bias variables for every layer are automatically generated and tracked. Also, the \"in_channel\" parameter for determining weight dimension is automatically inferred from the input. This allows you to focus on what layers you want to add to the model, without worrying as much about boilerplate code. \n",
    "\n",
    "- The repeat() function allows you to add the same layer multiple times. In terms of variable scoping, repeat() will add \"_#\" to the scope to distinguish the layers, so we'll still have layers of scope \"`conv1_1`, `conv1_2`, `conv2_1`, etc...\".\n",
    "\n",
    "- With slim.argscope(), we're able to specify defaults for common parameter arguments, such as the activation function or weights_initializer. Of course, these defaults can still be overridden in any individual layer, as demonstrated in the finally fully connected layer (fc8)..\n",
    "\n",
    "If you're reusing one of the famous architectures (like VGG-16), it becomes even easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "vgg = tf.contrib.slim.nets.vgg\n",
    "\n",
    "# Set up the data loading:\n",
    "images, labels = ...\n",
    "\n",
    "# Define the model:\n",
    "predictions = vgg.vgg16(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
